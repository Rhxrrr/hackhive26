## ğŸ§ Overview

**QAI** is an AI-first customer service quality assurance platform that understands conversationsâ€”not just transcripts. Upload or stream a customer service call and watch QAI automatically surface the moments that matter most. No more scrubbing through hours of audio, no more subjective scoringâ€”QAI listens alongside your quality team and turns conversations into actionable insights.

> *â€œShow me where the customer became frustrated and how the agent handled it.â€*.

QAI analyzes both **what is said** and **how itâ€™s said**, detecting tone shifts, empathy gaps, and resolution moments in real time or post-call. It aligns directly with your companyâ€™s QA rubric to generate explainable scores, detailed reports, and coaching-ready feedback.

---

## âœ¨ Why QAI?

- **Conversation-Aware QA** â€” Automatically detect **good**, **bad**, **uncertain**, and **needs improvement** moments throughout a call  
- **Tone & Sentiment Detection** â€” Track emotional drift like frustration, hesitation, and relief as conversations unfold  
- **Interactive Audio Timeline** â€” Jump directly to key moments instead of listening end-to-end  
- **Rubric-Based Scoring** â€” Score agents using your companyâ€™s existing QA marking scheme  
- **Real-Time Agent Coaching** â€” Surface live suggestions on empathy, tone, and sales techniques during active calls  
- **Explainable Reports** â€” Every score is backed by transcript evidence and timestamps  
- **Built for Quality Coaches** â€” Reduce manual review time by **50â€“70%** while reviewing more calls with greater consistency  

---

QAI turns quality assurance from a manual, reactive process into a **fast, consistent, and coach-driven workflow**â€”helping teams improve agent performance and customer experience at scale.

## ğŸš€ Features

### ğŸ™ï¸ AI-Powered Tools

| Feature | Description |
|------|-------------|
| **Conversation-Aware QA** | Analyze full customer service calls and automatically detect **good**, **bad**, **uncertain**, and **needs improvement** moments across the conversation |
| **Tone & Sentiment Detection** | Track emotional changes such as frustration, hesitation, and relief in real time or post-call using voice and language signals |
| **Interactive Audio Timeline** | Visual timeline with markers that let quality coaches jump directly to key moments instead of listening end-to-end |
| **Speaker-Labeled Transcripts** | Separate agent and customer dialogue with timestamps for faster review and context |
| **Rubric-Based Scoring** | Score agent performance using the companyâ€™s custom QA rubric and marking scheme |
| **Explainable QA Reports** | Generate detailed QA reports with scores, transcript evidence, and timestamps to support consistent evaluations |
| **Real-Time Agent Coaching** | Surface live suggestions during calls to improve tone, empathy, and objection handling |
| **Sales Guidance & Techniques** | Provide contextual sales tips and conversation strategies based on what the customer is saying |
| **Synthetic Call Generator** | Create realistic AI-generated customer service calls with emotional progression for testing and demos |
| **Scalable QA Workflow** | Review more calls in less time while maintaining consistency across reviewers |

## ğŸ› ï¸ Tech Stack

### ğŸ¨ Frontend
- **Next.js** â€” Application framework for fast, scalable web experiences  
- **React** â€” Interactive UI for timelines, transcripts, and QA dashboards  
- **TypeScript** â€” Type-safe data models for QA outputs and API contracts  
- **Tailwind CSS** â€” Modern, responsive styling with consistent design  

---

### ğŸ§  AI & APIs
- **OpenAI API** â€” Contextual analysis for tone detection, QA classification, scoring, and coaching insights  
- **Soniox API** â€” Real-time and batch speech-to-text with speaker separation and timestamps  

---

### âš™ï¸ Backend & Services
- **Node.js / Express** â€” Core backend for audio ingestion, QA orchestration, and API endpoints  

## âš¡ Quick Start

### âœ… Prerequisites
Make sure you have the following installed and set up:

- **Node.js 18+**
- **npm** or **pnpm**
- **OpenAI API key** (used for analysis, tone detection, coaching, and live feedback)
- **Soniox account** (used for real-time and batch transcription)  
  ğŸ‘‰ Get a key at: https://console.soniox.com

---

## ğŸ“¦ Installation
```bash
# Navigate to the project directory
cd hackhive26

# Install dependencies
npm install
```
---

## Environment Variables
Create a .env.local file in the project root and add the following variables:
```bash
# AI / Transcription
OPENAI_API_KEY=your_openai_key
SONIOX_API_KEY=your_soniox_key
```

---

## Run Development Server

```bash

# npm run dev

```
---

ğŸ‘‰ http://localhost:3000

## ğŸ“ Project Structure
```bash

hackhive26/
â”œâ”€â”€ app/                      # Next.js App Router
â”‚   â”œâ”€â”€ api/                  # API routes
â”‚   â”‚   â”œâ”€â”€ analyze/          # AI analysis endpoints
â”‚   â”‚   â”œâ”€â”€ transcribe/       # Audio transcription
â”‚   â”‚   â””â”€â”€ soniox/           # Soniox (tone, coaching, live feedback)
â”‚   â”œâ”€â”€ analytics/            # Analytics page
â”‚   â”œâ”€â”€ dashboard/            # Dashboard page
â”‚   â”œâ”€â”€ live/                 # Live call page
â”‚   â”œâ”€â”€ live-call/            # Live call page (alternate route)
â”‚   â”œâ”€â”€ qa/                   # QA review page
â”‚   â”œâ”€â”€ page.tsx              # Home page
â”‚   â”œâ”€â”€ layout.tsx            # Root layout
â”‚   â””â”€â”€ globals.css           # Global styles
â”‚
â”œâ”€â”€ components/               # Reusable React components
â”‚   â”œâ”€â”€ ui/                   # shadcn/ui components
â”‚   â”œâ”€â”€ analysis-panel.tsx    # Analysis panel
â”‚   â”œâ”€â”€ app-sidebar.tsx       # App sidebar
â”‚   â”œâ”€â”€ upload-zone.tsx       # Upload zone
â”‚   â”œâ”€â”€ waveform-timeline.tsx # Waveform timeline
â”‚   â””â”€â”€ theme-provider.tsx    # Theme provider
â”‚
â”œâ”€â”€ hooks/                    # Custom React hooks
â”‚   â”œâ”€â”€ use-mobile.ts
â”‚   â””â”€â”€ use-toast.ts
â”‚
â”œâ”€â”€ lib/                      # Utilities & helpers
â”‚   â””â”€â”€ utils.ts              # Helper functions
â”‚
â”œâ”€â”€ public/                   # Static assets
â”‚
â””â”€â”€ styles/                   # Stylesheets
    â””â”€â”€ globals.css


```
---
## âš ï¸  Challenges we ran into

- Inconsistent QA interpretations during subtle tone shifts  
- Overconfident classifications in ambiguous or low-confidence moments  
- Emotional tone changes gradually across conversations, making single-utterance analysis unreliable  
- Latency when running real-time transcription and QA analysis simultaneously  
- Heavy scoring logic not suitable for live call processing  
- Merge conflicts caused by rapid prompt and UI iteration  
- Inconsistent behavior across branches during experimentation  
- Early QA outputs felt like a black box for quality coaches  
- Difficulty validating AI decisions without emphasizing explainability

--- 


## ğŸ™ Acknowledgements

- **OpenAI** â€” Tone detection, contextual analysis, QA scoring, and live coaching insights  
- **Soniox** â€” Real-time and batch speech-to-text transcription with speaker separation

---

## ğŸ“¬ Contact

**Team:**
- Abinan Suthakaran
- Adam Marcelo
- Jordan Earle
- Hamzah Al-Hamadani



